---
title: "Progress Memo 1"
subtitle: |
  | Final Project 
  | Data Science 1 with R (STAT 301-1)
author: "Valerie Chu"
date: today

format:
  html:
    toc: true
    embed-resources: true
    code-fold: show
    link-external-newwindow: true

execute:
  warning: false
  
from: markdown+emoji 

---

::: {.callout-tip icon=false}

## Github Repo Link

[https://github.com/stat301-1-2023-fall/final-project-1-valerieyichu.git](https://github.com/stat301-1-2023-fall/final-project-1-valerieyichu.git)

:::
## Load Packages

```{r}
library(tidyverse)
```


## Load Data

```{r}

books <- read_delim("data/books.csv")
books_tags <- read_csv("data/book_tags.csv")
ratings <- read_csv("data/ratings.csv")
tags <- read_csv("data/tags.csv")
tbr <- read_csv("data/to_read.csv")

```

## Before we dive into the data — A quick introduction to Goodreads

**What is Goodreads?**

It's essentially what I think of as a combination of Twitter and Amazon for book lovers. 

These are a few of Goodread's draws. It allows users to:

- Categorize books on their bookshelves

- Write book reviews

- Find their next read

- Vote on their annual favorites across genres

- See what books their friends are reading

- Track the books they're reading, have read, and want to read

- See their personalized book recommendations. (Goodreads says "Our recommendation engine analyzes 20 billion data points to give suggestions tailored to your literary tastes.")

- Read community reviews

Officially, this is how Goodreads describes itself: "Goodreads is the world’s largest site for readers and book recommendations. Our mission is to help readers discover books they love and get more out of reading. Goodreads launched in January 2007."


## Data source

**I'm interested in analyzing user habits on Goodreads.** 

I arrived at this dataset through searching Kaggle and Google. As one Reddit user put it, this is **the** most comprehensive dataset for book data. 

This is what the Kaggle description says, "There have been good datasets for movies (Netflix, Movielens) and music (Million Songs) recommendation, but not for books. That is, until now."

This is the link to the "goodbooks-10k" dataset on Kaggle: 
[https://www.kaggle.com/datasets/zygmunt/goodbooks-10k](https://www.kaggle.com/datasets/zygmunt/goodbooks-10k)

The description in Kaggle links to a Github repo that has a more updated and comprehensive version of the "books" dataset, which is the one that I loaded in. **The Github repo below is where I got my five datasets from. I believe both the older and newer versions were created by the same person, or at least authorized by them, because the datasets are identical except for more variables being added to the new one. ** 

::: {.callout-tip icon=false}

## My Data Source

**[https://github.com/zygmuntz/goodbooks-10k](https://github.com/zygmuntz/goodbooks-10k)**

:::


## Why this data

The reason why I'm interested in this dataset is extremely simple: I love reading. And Goodreads is like the treasure trove of every reader. So being able to analyze Goodreads data/Goodreads user data seems super fun. 

As mentioned above, I'm interested in analyzing user habits on Goodreads. This is why I chose this dataset. I've spent several hours combing through Kaggle, Google, Reddit, and other places on the internet. As far as I can tell, this is the most comprehensive dataset about books and user readings habits I can find, freely available from the internet. It was scraped from Goodread's and Goodread users's publicly available data. 


An interesting sidenote: 

At one point, I stumbled across a dataset from the UCSD Book Graph:
[https://mengtingwan.github.io/data/goodreads.html#datasets](https://mengtingwan.github.io/data/goodreads.html#datasets)

However, the problem is that this dataset is around 4.1 GB. It's the only other dataset I found on the internet that's rumored to have more comprehensive reader user data than the one I found from Github user zygmuntz (the one linked in the section above). However this dataset from UCSD Book Graph is too big, and my computer can't load it without crashing. Hence, why I decided to use the "goodbooks-10k" dataset. 



## Potential data issues, Part 1

**Before I talk about data quality & complexity check, I want to first bring up potential data issues. Mainly, the reason why I have five datasets.**

There are five datasets relevant to achieving my goal of wanting to analyze user reading habits through Goodreads data. 

- The primary dataset that I will be using is the one I have saved as "books". 

- However, the other four datasets — "books_tags", "ratings", "tags", and "tbr" all contain additional data about user habits on Goodreads. 

- The good thing is, the other four datasets can all be joined with the "books" dataset to create one large dataset. For example, `goodreads_book_id` in the "book_tags" dataset corresponds with `goodreads_book_id` in the "books" dataset. Because every book has a unique `goodreads_book_id`. This is the case across all five datasets pertaining to Goodreads user habits. 


## Data quality & complexity check

As demonstrated above, I had no trouble reading in the data. I've also mentioned above what joining the data might look like. It can definitely be done, and probably with limited issues. 

**So, I've established that for now, I will be primarily focusing on the "books" dataset. That's where most of the data is.**

The books dataset:

- There are 10,000 observations.

- There are 23 variables.

- There are 17 numerical variables.

- There are 6 categorical variables.

Exploring missingness:
```{r}

naniar::gg_miss_var(books)

```
- These are the variables with missing values: `language_code`, `isbn`, `original_title`, `isbn13`, `original_publication_year`.

- But overall, there are no big missingness issues. 


## Potential data issues, Part 2

Some other potential data issues: 

- As far as I can tell, this dataset doesn't come with a codebook. However, the vast majority of variables — including all of the ones I'm interested in analyzing — have perfectly clear names. (ex. `isbn13`, `authors`, `original_title`, etc.) And luckily, between the READMEs in the Github and Kaggle versions of the books dataset, I know what most of the variables mean. 

## Misc

- For the most part, the "books" dataset is clean, organized, and has lots of data. 

I'm super excited to start working with it! 

